{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTZoCquRDAlK"
      },
      "source": [
        "[12- Music genre classification: Preparing the dataset](https://www.youtube.com/watch?v=szyGiObZymo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UkcGNHESC31k"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import os\n",
        "import math\n",
        "import librosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naCrYWhTUA5b",
        "outputId": "27eb0497-6ed8-4a4f-f952-5e62f8e53e02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Deep-Learning-for-Audio-with-Python'...\n",
            "remote: Enumerating objects: 505, done.\u001b[K\n",
            "remote: Counting objects: 100% (20/20), done.\u001b[K\n",
            "remote: Compressing objects: 100% (12/12), done.\u001b[K\n",
            "remote: Total 505 (delta 7), reused 20 (delta 7), pack-reused 485\u001b[K\n",
            "Receiving objects: 100% (505/505), 555.58 MiB | 25.70 MiB/s, done.\n",
            "Resolving deltas: 100% (8/8), done.\n",
            "Updating files: 100% (483/483), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CPF2002/Deep-Learning-for-Audio-with-Python.git\n",
        "# clone my repo that contains the gtzan training set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "bIGwSFlCDB5H"
      },
      "outputs": [],
      "source": [
        "DATASET_PATH = '/content/Deep-Learning-for-Audio-with-Python/Data'\n",
        "JSON_PATH = \"data_extract_music.json\"\n",
        "SAMPLE_RATE = 22050\n",
        "TRACK_DURATION = 30 # measured in seconds\n",
        "SAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "QEr5zWaVDDf-"
      },
      "outputs": [],
      "source": [
        "def save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n",
        "    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n",
        "\n",
        "        :param dataset_path (str): Path to dataset\n",
        "        :param json_path (str): Path to json file used to save MFCCs\n",
        "        :param num_mfcc (int): Number of coefficients to extract\n",
        "        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n",
        "        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n",
        "        :param: num_segments (int): Number of segments we want to divide sample tracks into\n",
        "        :return:\n",
        "        \"\"\"\n",
        "\n",
        "    # dictionary to store mapping, labels, and MFCCs\n",
        "    data = {\n",
        "        \"mapping\": [],\n",
        "        \"labels\": [],\n",
        "        \"mfcc\": []\n",
        "    }\n",
        "\n",
        "    samples_per_segment = int(SAMPLES_PER_TRACK / num_segments)\n",
        "    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment / hop_length)\n",
        "\n",
        "    # loop through all genre sub-folder\n",
        "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
        "\n",
        "        # ensure we're processing a genre sub-folder level\n",
        "        if dirpath is not dataset_path:\n",
        "\n",
        "            # save genre label (i.e., sub-folder name) in the mapping\n",
        "            semantic_label = dirpath.split(\"/\")[-1]\n",
        "            data[\"mapping\"].append(semantic_label)\n",
        "            print(\"\\nProcessing: {}\".format(semantic_label))\n",
        "\n",
        "            # process all audio files in genre sub-dir\n",
        "            for f in filenames:\n",
        "\n",
        "\t\t# load audio file\n",
        "                file_path = os.path.join(dirpath, f)\n",
        "                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n",
        "\n",
        "                # process all segments of audio file\n",
        "                for d in range(num_segments):\n",
        "\n",
        "                    # calculate start and finish sample for current segment\n",
        "                    start = samples_per_segment * d\n",
        "                    finish = start + samples_per_segment\n",
        "\n",
        "                    # extract mfcc\n",
        "                    mfcc = librosa.feature.mfcc(y=signal[start:finish],  \n",
        "                                                sr=sample_rate, n_mfcc=num_mfcc, \n",
        "                                                n_fft=n_fft, \n",
        "                                                hop_length=hop_length)\n",
        "                    mfcc = mfcc.T\n",
        "\n",
        "                    # store only mfcc feature with expected number of vectors\n",
        "                    if len(mfcc) == num_mfcc_vectors_per_segment:\n",
        "                        data[\"mfcc\"].append(mfcc.tolist())\n",
        "                        data[\"labels\"].append(i-1)\n",
        "                        #print(\"{}, segment:{}\".format(file_path, d+1))\n",
        "\n",
        "    # save MFCCs to json file\n",
        "    with open(json_path, \"w\") as fp:\n",
        "        json.dump(data, fp, indent=4)\n",
        "\n",
        "    print(\"Finished!\")\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qe2zR4tYDMVI",
        "outputId": "58641357-02d1-43ce-e7d4-2925c0224d5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing: genres_original\n",
            "\n",
            "Processing: blues\n",
            "\n",
            "Processing: hiphop\n",
            "\n",
            "Processing: classical\n",
            "\n",
            "Processing: country\n",
            "\n",
            "Processing: disco\n",
            "Finished!\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6QeDmaVDTRc"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}